{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f7f99d-7463-4885-9c59-16d3e1e7b954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mus/miniforge3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MultinomialNB from version 1.1.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/mus/miniforge3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the saved models\n",
    "modelsNS = {\n",
    "    'DecisionTree_N-S': 'DecisionTree_N-S.sav',\n",
    "    'NaiveBayes_N-S': 'NaiveBayes_N-S.sav',\n",
    "    'RandomForest_N-S': 'RandomForest_N-S.sav'\n",
    "}\n",
    "modelsEI = {\n",
    "    'DecisionTree_E-I': 'DecisionTree_E-I.sav',\n",
    "    'NaiveBayes_E-I': 'NaiveBayes_E-I.sav',\n",
    "    'RandomForest_E-I': 'RandomForest_E-I.sav',\n",
    "}\n",
    "\n",
    "modelsFT = {\n",
    "    'DecisionTree_F-T': 'DecisionTree_F-T.sav',\n",
    "    'NaiveBayes_F-T': 'NaiveBayes_F-T.sav',\n",
    "    'RandomForest_F-T': 'RandomForest_F-T.sav', \n",
    "}\n",
    "modelsJP = {\n",
    "    'DecisionTree_J-P': 'DecisionTree_J-P.sav',\n",
    "    'NaiveBayes_J-P': 'NaiveBayes_J-P.sav',\n",
    "    'RandomForest_J-P': 'RandomForest_J-P.sav',\n",
    "}\n",
    "\n",
    "\n",
    "loaded_modelsEI = {}\n",
    "for model_name, model_file in modelsEI.items():\n",
    "    loaded_model = pickle.load(open(model_file, 'rb'))\n",
    "    loaded_modelsEI[model_name] = loaded_model\n",
    "\n",
    "loaded_modelsFT = {}\n",
    "for model_name, model_file in modelsFT.items():\n",
    "    loaded_model = pickle.load(open(model_file, 'rb'))\n",
    "    loaded_modelsFT[model_name] = loaded_model\n",
    "\n",
    "loaded_modelsJP = {}\n",
    "for model_name, model_file in modelsJP.items():\n",
    "    loaded_model = pickle.load(open(model_file, 'rb'))\n",
    "    loaded_modelsJP[model_name] = loaded_model\n",
    "    \n",
    "loaded_modelsNS = {}\n",
    "for model_name, model_file in modelsNS.items():\n",
    "    loaded_model = pickle.load(open(model_file, 'rb'))\n",
    "    loaded_modelsNS[model_name] = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3492237b-fbd8-474b-90e2-648b9372f012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/mus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f916fa0-7ad7-4ce3-bd3d-76ad2baf582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/vwlktfw10794w_tk_lyhmlm00000gn/T/ipykernel_47888/2686593958.py:9: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  vectorizer = pickle.load(vec_file)\n",
      "/Users/mus/miniforge3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.1.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/mus/miniforge3/envs/tensorflow/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 1.1.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('cv_data.txt', 'r', encoding='utf-8') as file:\n",
    "    cv_text = file.read()\n",
    "\n",
    "# Create a DataFrame with a single row containing the CV data\n",
    "cv_df = pd.DataFrame({'text': [cv_text]})\n",
    "\n",
    "# Load the vectorizer used during training\n",
    "with open('vectorizer.pkl', 'rb') as vec_file:\n",
    "    vectorizer = pickle.load(vec_file)\n",
    "\n",
    "# Transform the CV data using the loaded vectorizer\n",
    "cv_vector = vectorizer.transform(cv_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5a7d1db-c9c3-44d9-8b7c-ec4ae0360072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTree_E-I, Prediction: [0]\n",
      "Model: NaiveBayes_E-I, Prediction: [0]\n",
      "Model: RandomForest_E-I, Prediction: [0]\n",
      "personality type : E \n"
     ]
    }
   ],
   "source": [
    "final_pers = []\n",
    "sumEI = 0\n",
    "for model_name, model in loaded_modelsEI.items():\n",
    "    prediction = model.predict(cv_vector)\n",
    "    print(f\"Model: {model_name}, Prediction: {prediction}\")\n",
    "    sumEI = sumEI + prediction\n",
    "if(sumEI>1):\n",
    "    print(\"personality type : I \")\n",
    "    final_pers.append(\"I\")\n",
    "else:\n",
    "    print(\"personality type : E \")\n",
    "    final_pers.append(\"E\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "482d6c5a-c5d3-49f1-8521-8bbc9d57dcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTree_F-T, Prediction: [0]\n",
      "Model: NaiveBayes_F-T, Prediction: [0]\n",
      "Model: RandomForest_F-T, Prediction: [0]\n",
      "personality type : F \n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for model_name, model in loaded_modelsFT.items():\n",
    "    prediction = model.predict(cv_vector)\n",
    "    print(f\"Model: {model_name}, Prediction: {prediction}\")\n",
    "    sum = sum + prediction\n",
    "\n",
    "if(sum>1):\n",
    "    print(\"personality type : T \")\n",
    "    final_pers.append(\"T\")\n",
    "else:\n",
    "    print(\"personality type : F \")\n",
    "    final_pers.append(\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83e18354-1be2-4e62-9c99-e816e7cde200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTree_J-P, Prediction: [0]\n",
      "Model: NaiveBayes_J-P, Prediction: [1]\n",
      "Model: RandomForest_J-P, Prediction: [0]\n",
      "personality type : J \n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for model_name, model in loaded_modelsJP.items():\n",
    "    prediction = model.predict(cv_vector)\n",
    "    print(f\"Model: {model_name}, Prediction: {prediction}\")\n",
    "    sum = sum + prediction\n",
    "\n",
    "if(sum>1):\n",
    "    print(\"personality type : P \")\n",
    "    final_pers.append(\"P\")\n",
    "else:\n",
    "    print(\"personality type : J \")\n",
    "    final_pers.append(\"J\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7aa15f94-4d88-43cd-81aa-6ca3fcca3909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTree_N-S, Prediction: [1]\n",
      "Model: NaiveBayes_N-S, Prediction: [1]\n",
      "Model: RandomForest_N-S, Prediction: [1]\n",
      "personality type : S \n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for model_name, model in loaded_modelsNS.items():\n",
    "    prediction = model.predict(cv_vector)\n",
    "    print(f\"Model: {model_name}, Prediction: {prediction}\")\n",
    "    sum = sum + prediction\n",
    "\n",
    "if(sum>1):\n",
    "    print(\"personality type : S \")\n",
    "    final_pers.append(\"S\")\n",
    "else:\n",
    "    print(\"personality type : N \")\n",
    "    final_pers.append(\"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "671f5aec-abf2-4464-879a-a115d1d68ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Personality Type :  ['E', 'F', 'J', 'S']\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Personality Type : \",final_pers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012315cf-1c42-4e25-98e3-b7c00d985f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
